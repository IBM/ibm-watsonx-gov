{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Metrics\n",
    "This notebook evaluates RAG metrics using IBM watsonx.governance SDK. It can evaluate RAG metrics by taking in the data containing contexts, question, answer and ground truth (Optional) information. The metrics result will be visualized using the `ModelInsights`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in Python 3.10 or greater runtime environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Compute RAG metrics using `evaluate_metrics`.\n",
    "- Visualize metrics result using `ModelInsights`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Step 1 - Install libraries](#install)\n",
    "- [Step 2 - Configuration](#configuration)\n",
    "- [Step 3 - Evaluate Metrics](#evaluate)\n",
    "- [Step 4 - Display the results](#display)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries<a name=\"install\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ibm-watsonx-gov[metrics,visualization]\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration <a name=\"configuration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your watsonx.governance credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.config import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"<EDIT_THIS>\",\n",
    "    api_key=\"<EDIT_THIS>\",\n",
    "    service_instance_id=\"<EDIT_THIS>\",\n",
    "\n",
    "    # Uncomment the following attributes when using watsonx.governance\n",
    "    # username=\"<EDIT_THIS>\",\n",
    "    # version=\"<EDIT_THIS>\",\n",
    "    # disable_ssl=\"<EDIT_THIS>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Metrics<a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step the input to the RAG application, its generated output, and the retrieved contexts are loaded. To get started, please use the sample CSV dataset file provided in this notebook. However, if you want to use your own RAG application and would like to evaluate it's output, the dataset can be loaded in the following cell and the configuration can be updated to read the specific columns in the dataset.\n",
    "\n",
    "### Loading your test data\n",
    "\n",
    "In this step, you can load your own sample RAG dataset in `input_df` and update the configuration object in the next step to match the column names from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"https://raw.githubusercontent.com/IBM/ibm-watsonx-gov/refs/heads/samples/notebooks/data/rag/rag_with_ground_truth.csv\")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the evaluator\n",
    "\n",
    "Once the dataset is loaded, need to configure the evaluator to specify what are the columns of interests in the data set and to specify which metrics to evaluate\n",
    "\n",
    "#### Dataset columns\n",
    "\n",
    "To configure the evaluator for the dataset, please update `question_field` to be the column name that contains the questions, `context_field` to be a list of column names that contains the contexts, and `output_fields` to have the column that contain the generated answer. Optionally, you can add the ground truth column name under `reference_fields`.\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "You can provide the metrics to evaluate in the `metrics` list. The metric evaluation method(i.e. the technique used to compute the metric) can be provided by specifying the `method` value when creating the metric object. In addition, you can also provide the metric groups under `metric_groups` which will evaluate all the metrics belonging to the specified group(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.config import GenAIConfiguration\n",
    "from ibm_watsonx_gov.metrics import ContextRelevanceMetric, FaithfulnessMetric, AnswerSimilarityMetric, AnswerRelevanceMetric\n",
    "from ibm_watsonx_gov.entities.enums import TaskType, MetricGroup\n",
    "\n",
    "question_field = \"question\"\n",
    "context_field = \"contexts\"\n",
    "\n",
    "config = GenAIConfiguration(\n",
    "    input_fields=[question_field, context_field],\n",
    "    question_field=question_field,\n",
    "    context_fields=[context_field],\n",
    "    output_fields=[\"answer\"],\n",
    "    reference_fields=[\"ground_truth\"],\n",
    "    task_type=TaskType.RAG,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    ContextRelevanceMetric(),\n",
    "    FaithfulnessMetric(),\n",
    "    AnswerSimilarityMetric(),\n",
    "    AnswerRelevanceMetric(),\n",
    "]\n",
    "\n",
    "metric_groups = [\n",
    "    MetricGroup.RETRIEVAL_QUALITY,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the metrics evaluation\n",
    "\n",
    "Create `MetricEvaluator` instance using the configuration and credentials. After that compute the desired metrics by invoking `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.clients.api_client import APIClient\n",
    "from ibm_watsonx_gov.evaluators import MetricsEvaluator\n",
    "\n",
    "evaluator = MetricsEvaluator(\n",
    "    api_client=APIClient(credentials=credentials),\n",
    "    configuration=config,\n",
    ")\n",
    "\n",
    "evaluation_result = evaluator.evaluate(\n",
    "    data=input_df,\n",
    "    metrics=metrics,\n",
    "    metric_groups=metric_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results  <a name=\"display\"></a>\n",
    "\n",
    "### Display the result table\n",
    "\n",
    "Now that the evaluation is done, display a table containing each record with its metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.display_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ModelInsights` visualization\n",
    "\n",
    "Finally, the evaluation result is displayed interactively using `ModelInsights`\n",
    "\n",
    "Notes:\n",
    "- The interactive visualization is supported only with Jupyter lab.\n",
    "- If the diagram is not displayed correctly or has missing components, please refresh the browser page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "evaluator.display_insights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrav2test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
