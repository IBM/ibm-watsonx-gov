{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Metrics\n",
    "This notebook evaluates RAG metrics using IBM watsonx.governance SDK. It can evaluate RAG metrics by taking in the data containing contexts, question, answer and ground truth(Optional) information. The metrics result can be visualized using the ModelInsights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in Python 3.10 or greater runtime environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Computes RAG metrics using evaluate_metrics.\n",
    "- Visualize metrics result using ModelInsights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Step 1 - Install libraries](#install)\n",
    "- [Step 2 - Configuration](#configuration)\n",
    "- [Step 3 - Evaluate Metrics](#evaluate)\n",
    "- [Step 4 - Display the results](#display)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries<a name=\"install\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-watsonx-gov[metrics,visualization]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration <a name=\"configuration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your watsonx.governance credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.config import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"<EDIT_THIS>\",\n",
    "    api_key=\"<EDIT_THIS>\",\n",
    "    service_instance_id=\"<EDIT_THIS>\",\n",
    "\n",
    "    # Uncomment the following attributes when using watsonx.governance\n",
    "    # username=\"<EDIT_THIS>\",\n",
    "    # version=\"<EDIT_THIS>\",\n",
    "    # disable_ssl=\"<EDIT_THIS>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Metrics<a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read RAG data from a file or from an application invoking the model and generating responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the data containing the application input and output from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"https://raw.githubusercontent.com/IBM/ibm-watsonx-gov/refs/heads/samples/notebooks/data/rag/rag_with_ground_truth.csv\")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create metrics configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.config import GenAIConfiguration\n",
    "from ibm_watsonx_gov.metrics import ContextRelevanceMetric, FaithfulnessMetric, AnswerSimilarityMetric\n",
    "from ibm_watsonx_gov.entities.enums import TaskType\n",
    "\n",
    "question_field = \"question\"\n",
    "context_field = \"contexts\"\n",
    "\n",
    "config = GenAIConfiguration(\n",
    "    input_fields=[question_field, context_field],\n",
    "    question_field=question_field,\n",
    "    context_fields=[context_field],\n",
    "    output_fields=[\"answer\"],\n",
    "    reference_fields=[\"ground_truth\", \"answer\"],\n",
    "    task_type=TaskType.RAG,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    ContextRelevanceMetric(method=\"sentence_bert_mini_lm\"),\n",
    "    FaithfulnessMetric(method=\"token_k_precision\"),\n",
    "    FaithfulnessMetric(method=\"sentence_bert_mini_lm\"),\n",
    "    AnswerSimilarityMetric(method=\"token_recall\"),\n",
    "    AnswerSimilarityMetric(method=\"sentence_bert_mini_lm\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.evaluate import evaluate_metrics\n",
    "\n",
    "evaluation_result = evaluate_metrics(\n",
    "    credentials=credentials,\n",
    "    configuration=config,\n",
    "    metrics=metrics,\n",
    "    data=input_df,\n",
    "    output_format=\"dataframe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results  <a name=\"display\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_gov.visualizations import display_table\n",
    "display_table(evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model insights based on the thresholds specified in the metrics configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from ibm_watsonx_gov.visualizations import ModelInsights\n",
    "\n",
    "model_insights = ModelInsights(configuration=config, metrics=metrics)\n",
    "model_insights.display_metrics(metrics_result=evaluation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrav2test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
