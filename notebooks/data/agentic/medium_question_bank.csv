input_text,ground_truth
"What is counterfactual fairness?","Counterfactual fairness is a fairness criterion used in machine learning to ensure that a model’s decisions remain unchanged if a protected attribute (e.g., race, gender) were different, while keeping everything else the same."
"How does IBM watsonx.governance check for prompt leakage?","IBM watsonx.governance runs your prompt through several different attack scenarios. The responses generated by the model are then compared to the original prompt using a semantic similarity score. The result is a score between 0 and 1, where 0 indicates low risk and 1 indicates high risk of leakage."
"What are various IBM watsonx.governance capabilities?","IBM watsonx.governance is an automated toolkit to govern both generative AI and predictive ML models on the IBM watsonx platform, providing complete end to end life cycle management of the models to tune, train, deploy, and govern them — to accelerate responsible, transparent, and explainable AI workflows."
"What does Grafana do?","Grafana is an open-source tool for visualizing and dashboarding data insights gathered from various sources — creating dashboards with charts, graphs,and alerts to monitor the systems and applications"
"What is concept drift?","Concept drift occurs when the statistical properties of the target variable change over time, causing a machine learning model’s predictions to become less accurate."
"What does IBM watsonx.governance Evaluation Studio do?","IBM watsonx.governance Evaluation Studio enables LLM application developers to evaluate and compare generative AI assets using quality metrics and customizable criteria tailored to specific application needs. Developers can assess the performance of multiple assets simultaneously and compare results to identify the best LLM, prompt, or prompt parameters for their LLM-powered application."
"How can technology help in process governance?","It can help define, automate and govern the process that needs to be followed as a prompt (or AI model) moves from development to validation to production. It can identify the set of tests that need to be done before the prompt is deployed to production and automate the end to end flow so that teams do not inadvertently end up deploying prompts to production bypassing one or more of the identified tests"
"What are the challenges with AI model validation?","Software execs boast about robust deployment processes, but AI model validation often lacks rigor. It's complex, requiring expertise in bias detection, model metrics, and drift analysis. Skilled validators are scarce, and the absence of standardized validation methods results in inconsistent documentation across enterprises, making AI validation a persistent challenge."
"What are the different steps in AI Lifecycle?","The AI lifecycle consists of several key steps:  \n1. **Model Creation Request** – Defines business needs, constraints, and expected impact.  \n2. **Model Development** – Data scientists build the model.  \n3. **Model Validation** – Validators assess fairness, accuracy, and drift.  \n4. **Model Approval** – Approvers review validation results for deployment readiness.  \n5. **Model Deployment** – Approved models go into production.  \n6. **Model Monitoring** – Continuously tracks fairness, drift, and quality.  \n7. **Model Retirement** – Decommissioning when the model is no longer needed."
"What is Azure Databricks?","This cloud-based platform, built on Apache Spark, enables collaborative data tasks, including ingestion, engineering, and machine learning model development."